README en français

# Projet 1 : Plateforme d’analyse prédictive

## Description
Ce projet implémente un pipeline complet de machine learning sur un dataset open data (Titanic) : acquisition, nettoyage, exploration, modélisation, optimisation, évaluation, et déploiement via une API REST.

## Structure
- `main.py` : workflow principal
- `data_preprocessing.py` : nettoyage et visualisation des données
- `model_training.py` : entraînement et évaluation des modèles
- `hyperparameter_tuning.py` : optimisation des hyperparamètres
- `api_server.py` : déploiement de l’API REST
- `utils.py` : fonctions utilitaires
- `requirements.txt` : dépendances Python

## Installation
```bash
pip install -r requirements.txt
```

## Utilisation
1. Télécharger le dataset Titanic depuis Kaggle.
2. Lancer `main.py` pour exécuter le pipeline complet.
3. Utiliser `api_server.py` pour démarrer le serveur API.

## Contributions
Contributions et améliorations sont les bienvenues via pull requests.

***

README in English

# Project 1: Predictive Analysis Platform

## Description
This project implements a full machine learning pipeline on an open data dataset (Titanic): data acquisition, cleaning, exploration, modeling, tuning, evaluation, and deployment via REST API.

## Structure
- `main.py`: main workflow
- `data_preprocessing.py`: data cleaning and visualization
- `model_training.py`: training and evaluation of models
- `hyperparameter_tuning.py`: hyperparameter optimization
- `api_server.py`: REST API deployment
- `utils.py`: utility functions
- `requirements.txt`: Python dependencies

## Installation
```bash
pip install -r requirements.txt
```

## Usage
1. Download the Titanic dataset from Kaggle.
2. Run `main.py` to execute the full pipeline.
3. Use `api_server.py` to start the API server.

## Contributions
Contributions and improvements are welcome via pull requests.

## Sources
https://www.kaggle.com/competitions/titanic/data